{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import collections\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset\nimport math\nimport torchvision\nfrom torch import  nn\nfrom tqdm import tqdm\nfrom torch import nn\nfrom time import time as  time\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-01-24T13:26:53.937014Z","iopub.execute_input":"2022-01-24T13:26:53.937612Z","iopub.status.idle":"2022-01-24T13:26:55.579528Z","shell.execute_reply.started":"2022-01-24T13:26:53.937520Z","shell.execute_reply":"2022-01-24T13:26:55.578775Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nclass My_dataloader(Dataset):\n    def __init__(self,data_dir,transform,filename_list,label_list = None,mode = 'train'):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.data_filename = filename_list\n        self.mode = mode\n        if self.mode == 'train':\n            self.label_list = torch.tensor(label_list)    #label是一个数字列表\n    def __getitem__(self, item):\n        file_path = os.path.join(self.data_dir, list(self.data_filename)[item])\n        img = Image.open(file_path)\n        img = self.transform(img)\n        if self.mode == 'train':\n            label = self.label_list[item]\n            return img,label\n        else:\n            return img\n    def __len__(self):\n        return len(self.data_filename)\n\ndef read_train_labels(fname):\n    \"\"\"读取 `fname` 来给标签字典返回一个文件名。\"\"\"\n    with open(fname, 'r') as f:\n        # 跳过文件头行 (列名)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n\ndef read_test(fname):\n    with open(fname, 'r') as f:\n        # 跳过文件头行 (列名)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',')[0] for l in lines]\n    return tokens\n\ndef class_to_num(data_dict):\n    classes = sorted(set(data_dict.values()))\n    num = [l for l in range(len(classes))]\n    return dict(zip(classes,num))\n\ndef num_to_class(data_dict):\n    classes = sorted(set(data_dict.values()))\n    num = [l for l in range(len(classes))]\n    return dict(zip(num,classes))\n\ndef tain_val_list(data_dict,class_num,valid_ratio):\n    n = collections.Counter(data_dict.values()).most_common()[-1][1]\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    train_dict = {}\n    val_dict = {}\n    count = {}\n    for key,value in data_dict.items():\n        if value not in count or count[value] < n_valid_per_label:\n            val_dict[key] = class_num[value]\n            count[value] = count.get(value, 0) + 1\n        else:\n            train_dict[key] = class_num[value]\n    return  train_dict,val_dict\n\ndef test(data_dir,train_csv_filename,test_csv_filename):\n    train_all = read_train_labels(os.path.join(data_dir,train_csv_filename))\n    test_all = read_test(os.path.join(data_dir,test_csv_filename))\n    class_num = class_to_num(train_all)\n    num_class = num_to_class(train_all)\n    train_dict,val_dict = tain_val_list(train_all,class_num,0.1)\n    # print(list(val_dict.values()))\n    train_list = train_dict.keys()\n    train_label = list(train_dict.values())\n    val_list = val_dict.keys()\n    val_label = list(val_dict.values())\n    # print(len(train_list),len(train_label),len(test_list),len(test_label))\n    train_loader = My_dataloader(data_dir,torchvision.transforms.ToTensor(),train_list,train_label)\n    val_loader = My_dataloader(data_dir, torchvision.transforms.ToTensor(), val_list, val_label)\n    test_loader = My_dataloader(data_dir,torchvision.transforms.ToTensor(),test_all,mode='test')\n    return train_loader,val_loader,test_loader,num_class\n\n\ndef transform_convert(img_tensor, transform):\n    \"\"\"\n    param img_tensor: tensor\n    param transforms: torchvision.transforms\n    \"\"\"\n    if 'Normalize' in str(transform):\n        normal_transform = list(filter(lambda x: isinstance(x, transforms.Normalize), transform.transforms))\n        mean = torch.tensor(normal_transform[0].mean, dtype=img_tensor.dtype, device=img_tensor.device)\n        std = torch.tensor(normal_transform[0].std, dtype=img_tensor.dtype, device=img_tensor.device)\n        img_tensor.mul_(std[:, None, None]).add_(mean[:, None, None])\n\n    img_tensor = img_tensor.transpose(0, 2).transpose(0, 1)  # C x H x W  ---> H x W x C\n\n    if 'ToTensor' in str(transform) or img_tensor.max() < 1:\n        img_tensor = img_tensor.detach().numpy() * 255\n\n    if isinstance(img_tensor, torch.Tensor):\n        img_tensor = img_tensor.numpy()\n\n    if img_tensor.shape[2] == 3:\n        img = Image.fromarray(img_tensor.astype('uint8')).convert('RGB')\n    elif img_tensor.shape[2] == 1:\n        img = Image.fromarray(img_tensor.astype('uint8')).squeeze()\n    else:\n        raise Exception(\"Invalid img shape, expected 1 or 3 in axis 2, but got {}!\".format(img_tensor.shape[2]))\n\n    return img\n\n\n\ndef train(net,train_iter,test_iter,epochs,lr,device):\n    net.to(device)\n    loss = nn.CrossEntropyLoss()\n    optim = torch.optim.Adam(net.parameters(),lr = lr)\n    for epoch in range(epochs):\n        start = time()\n        train_loss = []\n        train_accs = []\n        for batch in tqdm(train_iter):\n            X,y = batch\n            X,y = X.to(device),y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat,y)\n            optim.zero_grad()\n            l.backward()\n            optim.step()\n            acc = (y_hat.argmax(dim=-1) == y).float().mean()\n            train_loss.append(l.item())\n            train_accs.append(acc)\n        train_loss = sum(train_loss) / len(train_loss)\n        train_accs = sum(train_accs) / len(train_accs)\n\n        test_loss = []\n        test_accs = []\n        net.eval()\n        for batch in tqdm(test_iter):\n            X,y = batch\n            X,y = X.to(device),y.to(device)\n            with torch.no_grad():\n                y_hat = net(X)\n            l = loss(y_hat,y)\n            acc = (y_hat.argmax(dim=-1) == y).float().mean()\n            test_loss.append(l.item())\n            test_accs.append(acc)\n        test_loss = sum(test_loss) / len(test_loss)\n        test_accs = sum(test_accs) / len(test_accs)\n        print('  ')\n        print(f\"[  Time | {epoch + 1:03d}/{epochs:03d} ] time = {time() - start:.5f}\")\n        print(f\"[ Train | {epoch + 1:03d}/{epochs:03d} ] loss = {train_loss:.5f}, acc = {train_accs:.5f}\")\n        print(f\"[ Valid | {epoch + 1:03d}/{epochs:03d} ] loss = {test_loss:.5f}, acc = {test_accs:.5f}\")\n\n\ndef get_device():\n    return 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndef pred(net,test_iter,filename,num_class,device,saveFileName):\n    net.eval()\n    predictions = []\n    preds = []\n    for X in tqdm(test_iter):\n        X = X.to(device)\n        with torch.no_grad():\n            y_hat = net(X)\n        predictions.extend(y_hat.argmax(dim = -1).cpu().numpy().tolist())\n    for i in predictions:\n        preds.append(num_class[i])\n    test_data = pd.read_csv(filename)\n    test_data['label'] = pd.Series(preds)\n    submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n    submission.to_csv(saveFileName, index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T13:26:55.581219Z","iopub.execute_input":"2022-01-24T13:26:55.581462Z","iopub.status.idle":"2022-01-24T13:26:55.618529Z","shell.execute_reply.started":"2022-01-24T13:26:55.581427Z","shell.execute_reply":"2022-01-24T13:26:55.617876Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"net =torchvision.models.alexnet(pretrained=True)\nnet.classifier = nn.Sequential(\n    nn.Linear(9216,1024),\n    nn.ReLU(),\n    nn.Dropout(p=0.5),\n    nn.Linear(1024,176),\n    nn.LogSoftmax(dim=1)\n)\nnet","metadata":{"execution":{"iopub.status.busy":"2022-01-24T13:26:55.619760Z","iopub.execute_input":"2022-01-24T13:26:55.620112Z","iopub.status.idle":"2022-01-24T13:26:57.889884Z","shell.execute_reply.started":"2022-01-24T13:26:55.620077Z","shell.execute_reply":"2022-01-24T13:26:57.889089Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = get_device()\n\ndata_dir = '../input/classify-leaves'\ntrain_csv_filename = 'train.csv'\ntest_csv_filename = 'test.csv'\nsaveFileName = 'my_first_sub.csv'\nbatch_size = 1024\n\ntrain_loader,val_loader,test_loader,num_class= test(data_dir, train_csv_filename, test_csv_filename)\ntrain_iter = torch.utils.data.DataLoader(train_loader, batch_size, shuffle=True,drop_last=True)\nvalid_iter = torch.utils.data.DataLoader(val_loader, batch_size, shuffle=False,drop_last=False)\ntest_iter = torch.utils.data.DataLoader(test_loader, batch_size, shuffle=False,drop_last=False)\n\n\nepoch = 1\nlr = 0.001\n\ntrain(net,train_iter,valid_iter,epoch,lr,device)\npred(net,test_iter,os.path.join(data_dir,test_csv_filename),num_class,device,saveFileName)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T13:26:57.891538Z","iopub.execute_input":"2022-01-24T13:26:57.892215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}